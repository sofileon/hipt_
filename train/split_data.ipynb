{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import patchify\n",
    "import matplotlib.pyplot as plt\n",
    "running_in= '/mnt/CPG'#'/data/pathology'#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train,tune, test splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7019 WSI (catania+radboud):\n",
      " training      5468\n",
      "validation    1403\n",
      "testing        148\n",
      "Name: split, dtype: int64\n",
      "         pa    name category category2  normal  abnormal    split  \\\n",
      "0  17-10997  110849       ni   catania       1         0  testing   \n",
      "1  17-15278  128253      hgd   catania       0         1  testing   \n",
      "2  17-15545  129312      lgd   catania       0         1  testing   \n",
      "3  17-19372  143950   cancer   catania       0         1  testing   \n",
      "4  17-19392  144484   cancer   catania       0         1  testing   \n",
      "\n",
      "            classes  ni  hyperplastic  lgd  hgd  cancer  \n",
      "0                ni   1             0    0    0       0  \n",
      "1           lgd hgd   0             0    1    1       0  \n",
      "2  hyperplastic lgd   0             1    1    0       0  \n",
      "3            cancer   0             0    0    0       1  \n",
      "4            cancer   0             0    0    0       1  \n",
      "6943 WSI (just radboud):\n",
      " training      5468\n",
      "validation    1403\n",
      "testing         72\n",
      "Name: split, dtype: int64\n",
      "                pa                     name category category2  normal  \\\n",
      "76  EX_S03_P000001  EX_S03_P000001_C0001_B1   cancer      rumc       0   \n",
      "77  EX_S03_P000002  EX_S03_P000002_C0001_B2      lgd      rumc       0   \n",
      "78  EX_S03_P000003  EX_S03_P000003_C0001_B1   cancer      rumc       0   \n",
      "79  EX_S03_P000003  EX_S03_P000003_C0001_B2      lgd      rumc       0   \n",
      "80  EX_S03_P000004  EX_S03_P000004_C0001_B2      hgd      rumc       0   \n",
      "\n",
      "    abnormal       split  ni  hyperplastic  lgd  hgd  cancer  \n",
      "76         1    training   0             0    0    1       1  \n",
      "77         1  validation   0             0    1    0       0  \n",
      "78         1    training   0             0    0    0       1  \n",
      "79         1    training   0             0    1    0       0  \n",
      "80         1     testing   0             0    0    1       0  \n"
     ]
    }
   ],
   "source": [
    "witali_split=pd.read_csv(f'{running_in}/projects/Examode/wsi_experiments/colon/configs/colon_fold0.csv')\n",
    "print(f'{len(witali_split)} WSI (catania+radboud):\\n {witali_split.split.value_counts()}')\n",
    "print(witali_split.head())\n",
    "#Remove catania from the split\n",
    "witali_split=witali_split[witali_split.category2!='catania']\n",
    "witali_split.drop('classes',axis=1,inplace=True)\n",
    "print(f'{len(witali_split)} WSI (just radboud):\\n {witali_split.split.value_counts()}')\n",
    "print(witali_split.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal class: 4945\n",
      "ni              4098\n",
      "hyperplastic     847\n",
      "Name: category, dtype: int64\n",
      "Abnormal class: 1998\n",
      "lgd       1501\n",
      "cancer     296\n",
      "hgd        201\n",
      "Name: category, dtype: int64\n",
      "--------------------------------------------------\n",
      "Splits:\n",
      "training      5468\n",
      "validation    1403\n",
      "testing         72\n",
      "Name: split, dtype: int64\n",
      "Training--------------------\n",
      "ni              3260\n",
      "lgd             1189\n",
      "hyperplastic     651\n",
      "cancer           222\n",
      "hgd              146\n",
      "Name: category, dtype: int64\n",
      "Validation--------------------\n",
      "ni              824\n",
      "lgd             292\n",
      "hyperplastic    184\n",
      "cancer           60\n",
      "hgd              43\n",
      "Name: category, dtype: int64\n",
      "Testing--------------------\n",
      "lgd             20\n",
      "cancer          14\n",
      "ni              14\n",
      "hgd             12\n",
      "hyperplastic    12\n",
      "Name: category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#count the category of each image\n",
    "print('Normal class: '+ str(witali_split.where(witali_split.normal==1).dropna()['category'].count()))\n",
    "print(witali_split.where(witali_split.normal==1).dropna()['category'].value_counts())\n",
    "print('Abnormal class: '+ str(witali_split.where(witali_split.abnormal==1).dropna()['category'].count()))\n",
    "print(witali_split.where(witali_split.abnormal==1).dropna()['category'].value_counts())\n",
    "print('-'*50)\n",
    "print('Splits:')\n",
    "print(witali_split.split.value_counts())\n",
    "print('Training'+'-'*20)\n",
    "print(witali_split.where(witali_split.split=='training').dropna()['category'].value_counts())\n",
    "print('Validation'+'-'*20)\n",
    "print(witali_split.where(witali_split.split=='validation').dropna()['category'].value_counts())\n",
    "print('Testing'+'-'*20)\n",
    "print(witali_split.where(witali_split.split=='testing').dropna()['category'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create the csv with the training,validation and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_wsi=pd.read_csv(f'{running_in}/projects/pathology-self-supervision/data/examode_colon/processed_wsi2region_h5.csv')\n",
    "#get a df from witali split with the wsi contained in processed_wsi\n",
    "real_split=witali_split[witali_split.name.isin(processed_wsi.WSI_name)]\n",
    "split={'training':'train', 'validation':'tune', 'testing':'test'}\n",
    "saving_dir=f'{running_in}/projects/pathology-self-supervision/data/examode_colon/WSI_experiments'\n",
    "for k,v in split.items():\n",
    "    with open(f'{saving_dir}/{v}.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['slide_id','label'])\n",
    "        for index, row in real_split.where(real_split.split==k).dropna().iterrows():\n",
    "            writer.writerow([row['name'], int(row['abnormal'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing to extract regions from 434 images that are in the witali split\n",
      "There are 54 images in my pretraining that are not in Witalis split\n"
     ]
    }
   ],
   "source": [
    "witali_names=witali_split.name.to_list()\n",
    "processed_names=processed_wsi.WSI_name.to_list()\n",
    "missing_names_2=[name for name in processed_names if name not in witali_names]\n",
    "missing_names=[name for name in witali_names if name not in processed_names]\n",
    "print(f'Missing to extract regions from {len(missing_names)} images that are in the witali split')\n",
    "print(f'There are {len(missing_names_2)} images in my pretraining that are not in Witalis split')\n",
    "#Get the a dataframe with the missing names from witali split dataframe\n",
    "missing_df=witali_split[witali_split.name.isin(missing_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colon_non_cancer_wo_d    39\n",
       "colon_cancer_wo_d         7\n",
       "colon_non_cancer_lgd      5\n",
       "colon_non_cancer_hgd      3\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_images=processed_wsi[processed_wsi.WSI_name.isin(missing_names_2)]\n",
    "extra_images.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Normal class:\n",
      "ni    432\n",
      "Name: category, dtype: int64\n",
      "Missing Abnormal class:\n",
      "lgd    2\n",
      "Name: category, dtype: int64\n",
      "------------------------------\n",
      "Missing Splits:\n",
      "training      352\n",
      "validation     82\n",
      "Name: split, dtype: int64\n",
      "Missing Training--------------------\n",
      "ni     351\n",
      "lgd      1\n",
      "Name: category, dtype: int64\n",
      "Missing Validation--------------------\n",
      "ni     81\n",
      "lgd     1\n",
      "Name: category, dtype: int64\n",
      "Missing Testing--------------------\n",
      "No missing testing images\n"
     ]
    }
   ],
   "source": [
    "print('Missing Normal class:')\n",
    "print(missing_df.where(missing_df.normal == 1).dropna()['category'].value_counts())\n",
    "print('Missing Abnormal class:')\n",
    "print(missing_df.where(missing_df.abnormal == 1).dropna()['category'].value_counts())\n",
    "print('-'*30)\n",
    "print('Missing Splits:')\n",
    "print(missing_df.split.value_counts())\n",
    "print('Missing Training'+'-'*20)\n",
    "print(missing_df.where(missing_df.split == 'training').dropna()['category'].value_counts() if len(missing_df.where(\n",
    "    missing_df.split == 'training').dropna()['category'].value_counts()) > 0 else 'No missing training images')\n",
    "print('Missing Validation'+'-'*20)\n",
    "print(missing_df.where(missing_df.split == 'validation').dropna()['category'].value_counts()if len(missing_df.where(\n",
    "    missing_df.split == 'validation').dropna()['category'].value_counts()) > 0 else 'No missing validation images')\n",
    "print('Missing Testing'+'-'*20)\n",
    "print(missing_df.where(missing_df.split == 'testing').dropna()['category'].value_counts() if len(missing_df.where(\n",
    "    missing_df.split == 'testing').dropna()['category'].value_counts()) > 0 else 'No missing testing images')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can say that I am pretraining with 54 wholeslide images not in Witali split, and that I will train the last block from HIPT with 434 unseen wholeslide images during pretraining. \n",
    "\n",
    "I have the whole test set (72 images) processed.\n",
    "\n",
    "From those 434 missing images to process, 432 (351 in train/81 in validation) are from ni category (class normal) which is the category with more samples (3260 in training/824 in validation for a total of 4084).The other 2 (1 in train/1 in validation) images are from the lgd category (class abnormal) which is the category of abnormal with more samples (1189 in training/292 in validation for a total of 1481)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pa</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>category2</th>\n",
       "      <th>normal</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>split</th>\n",
       "      <th>ni</th>\n",
       "      <th>hyperplastic</th>\n",
       "      <th>lgd</th>\n",
       "      <th>hgd</th>\n",
       "      <th>cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>EX_S03_P001118</td>\n",
       "      <td>EX_S03_P001118_C0001_B1</td>\n",
       "      <td>ni</td>\n",
       "      <td>rumc</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>EX_S03_P001230</td>\n",
       "      <td>EX_S03_P001230_C0001_B1</td>\n",
       "      <td>ni</td>\n",
       "      <td>rumc</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>EX_S03_P001268</td>\n",
       "      <td>EX_S03_P001268_C0001_B2</td>\n",
       "      <td>lgd</td>\n",
       "      <td>rumc</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5605</th>\n",
       "      <td>EX_S03_P003261</td>\n",
       "      <td>EX_S03_P003261_C0001_B3</td>\n",
       "      <td>lgd</td>\n",
       "      <td>rumc</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6237</th>\n",
       "      <td>EX_S03_P003690</td>\n",
       "      <td>EX_S03_P003690_C0001_B1</td>\n",
       "      <td>ni</td>\n",
       "      <td>rumc</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6588</th>\n",
       "      <td>EX_S03_P003899</td>\n",
       "      <td>EX_S03_P003899_C0001_B2</td>\n",
       "      <td>ni</td>\n",
       "      <td>rumc</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6606</th>\n",
       "      <td>EX_S03_P003909</td>\n",
       "      <td>EX_S03_P003909_C0001_B2</td>\n",
       "      <td>ni</td>\n",
       "      <td>rumc</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pa                     name category category2  normal  \\\n",
       "1802  EX_S03_P001118  EX_S03_P001118_C0001_B1       ni      rumc       1   \n",
       "1994  EX_S03_P001230  EX_S03_P001230_C0001_B1       ni      rumc       1   \n",
       "2078  EX_S03_P001268  EX_S03_P001268_C0001_B2      lgd      rumc       0   \n",
       "5605  EX_S03_P003261  EX_S03_P003261_C0001_B3      lgd      rumc       0   \n",
       "6237  EX_S03_P003690  EX_S03_P003690_C0001_B1       ni      rumc       1   \n",
       "6588  EX_S03_P003899  EX_S03_P003899_C0001_B2       ni      rumc       1   \n",
       "6606  EX_S03_P003909  EX_S03_P003909_C0001_B2       ni      rumc       1   \n",
       "\n",
       "      abnormal       split  ni  hyperplastic  lgd  hgd  cancer  \n",
       "1802         0  validation   1             0    0    0       0  \n",
       "1994         0    training   1             0    0    0       0  \n",
       "2078         1  validation   0             0    1    0       0  \n",
       "5605         1    training   0             0    1    0       0  \n",
       "6237         0    training   1             0    0    0       0  \n",
       "6588         0    training   1             0    0    0       0  \n",
       "6606         0    training   1             0    0    0       0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsi_path = list(Path(\n",
    "    f\"{running_in}/archives/gastrointestinal/examode_biopsies_radboudumc_colon/packed_blocks_sp05/packed\").rglob(\"*.tif\"))\n",
    "wsi_names = [path.stem for path in wsi_path]\n",
    "missing_2_get_regions = [name for name in missing_names if name in wsi_names]\n",
    "wsi_in_neither=[name for name in wsi_names if name not in processed_names and name not in witali_names] #WSI images that are in Blissey but not in Witalis split nor in my pretraining(not in the ggt excel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However the 427/434 images missing are not in Blissey. Five images from the wsi in blissey are from normal class (4 train/1 val) and two from abnormal class (1 train/1 val). \n",
    "\n",
    "So after processing those, I would be left with 427 (347 in train/80 in validation) from ni category (class normal) missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do a csv file with the missing names that are not in blissey but in Witalis split (I would like to extract regions from them to make the training results comparable with Witalis results)\n",
    "missing_df[~missing_df.name.isin(missing_2_get_regions)].to_csv(f'{saving_dir}/missing_in_blissey.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pa</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>category2</th>\n",
       "      <th>normal</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>split</th>\n",
       "      <th>ni</th>\n",
       "      <th>hyperplastic</th>\n",
       "      <th>lgd</th>\n",
       "      <th>hgd</th>\n",
       "      <th>cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>EX_S03_P001118</td>\n",
       "      <td>EX_S03_P001118_C0001_B1</td>\n",
       "      <td>ni</td>\n",
       "      <td>rumc</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>EX_S03_P001230</td>\n",
       "      <td>EX_S03_P001230_C0001_B1</td>\n",
       "      <td>ni</td>\n",
       "      <td>rumc</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>EX_S03_P001268</td>\n",
       "      <td>EX_S03_P001268_C0001_B2</td>\n",
       "      <td>lgd</td>\n",
       "      <td>rumc</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5605</th>\n",
       "      <td>EX_S03_P003261</td>\n",
       "      <td>EX_S03_P003261_C0001_B3</td>\n",
       "      <td>lgd</td>\n",
       "      <td>rumc</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6237</th>\n",
       "      <td>EX_S03_P003690</td>\n",
       "      <td>EX_S03_P003690_C0001_B1</td>\n",
       "      <td>ni</td>\n",
       "      <td>rumc</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6588</th>\n",
       "      <td>EX_S03_P003899</td>\n",
       "      <td>EX_S03_P003899_C0001_B2</td>\n",
       "      <td>ni</td>\n",
       "      <td>rumc</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6606</th>\n",
       "      <td>EX_S03_P003909</td>\n",
       "      <td>EX_S03_P003909_C0001_B2</td>\n",
       "      <td>ni</td>\n",
       "      <td>rumc</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pa                     name category category2  normal  \\\n",
       "1802  EX_S03_P001118  EX_S03_P001118_C0001_B1       ni      rumc       1   \n",
       "1994  EX_S03_P001230  EX_S03_P001230_C0001_B1       ni      rumc       1   \n",
       "2078  EX_S03_P001268  EX_S03_P001268_C0001_B2      lgd      rumc       0   \n",
       "5605  EX_S03_P003261  EX_S03_P003261_C0001_B3      lgd      rumc       0   \n",
       "6237  EX_S03_P003690  EX_S03_P003690_C0001_B1       ni      rumc       1   \n",
       "6588  EX_S03_P003899  EX_S03_P003899_C0001_B2       ni      rumc       1   \n",
       "6606  EX_S03_P003909  EX_S03_P003909_C0001_B2       ni      rumc       1   \n",
       "\n",
       "      abnormal       split  ni  hyperplastic  lgd  hgd  cancer  \n",
       "1802         0  validation   1             0    0    0       0  \n",
       "1994         0    training   1             0    0    0       0  \n",
       "2078         1  validation   0             0    1    0       0  \n",
       "5605         1    training   0             0    1    0       0  \n",
       "6237         0    training   1             0    0    0       0  \n",
       "6588         0    training   1             0    0    0       0  \n",
       "6606         0    training   1             0    0    0       0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Do a csv file with the missing images paths\n",
    "wsi_2_be_processed=[wsi_p for wsi_p in wsi_path if wsi_p.stem in missing_2_get_regions]\n",
    "# replace /mnt/CPG with /data/pathology\n",
    "wsi_2_be_processed=[str(wsi_p).replace('/mnt/CPG','/data/pathology') for wsi_p in wsi_2_be_processed]\n",
    "mask_path =list(Path(f\"{running_in}/archives/gastrointestinal/examode_biopsies_radboudumc_colon/packed_blocks_sp05/tissue_masks\").rglob(\"*.tif\"))\n",
    "#get the mask path for the missing images\n",
    "mask_2_be_processed=[mask_p for mask_p in mask_path if (\"_\").join(mask_p.stem.split(\"_\")[:-1]) in missing_2_get_regions]\n",
    "# replace /mnt/CPG with /data/pathology\n",
    "mask_2_be_processed=[str(mask_p).replace('/mnt/CPG','/data/pathology') for mask_p in mask_2_be_processed]\n",
    "missing_df[missing_df.name.isin(missing_2_get_regions)] #Images that are in Blissey and in Witalis split but not in my pretraining, I will get the regions and extract features from them to train the last HIPT layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_2_be_processed.sort()\n",
    "wsi_2_be_processed.sort()\n",
    "#Create a csv file with the missing images paths\n",
    "csv_dir=f'{running_in}/projects/pathology-self-supervision/H2SP_csv/colon_not_in_pretraining.csv'\n",
    "with open(csv_dir, 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['slide_path','mask_path'])\n",
    "    writer.writerows(zip(wsi_2_be_processed,mask_2_be_processed))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/data/pathology/archives/gastrointestinal/examode_biopsies_radboudumc_colon/packed_blocks_sp05/packed/EX_S03_P001268_C0001_B2.tif is just pixelated stuff\n",
    "/data/pathology/archives/gastrointestinal/examode_biopsies_radboudumc_colon/packed_blocks_sp05/packed/EX_S03_P003261_C0001_B3.tif is just pixelated stuff\n",
    "/data/pathology/archives/gastrointestinal/examode_biopsies_radboudumc_colon/packed_blocks_sp05/packed/EX_S03_P003690_C0001_B1.tif is just pixelated stuff\n",
    "/data/pathology/archives/gastrointestinal/examode_biopsies_radboudumc_colon/packed_blocks_sp05/packed/EX_S03_P003899_C0001_B2.tif is just pixelated stuff\n",
    "/data/pathology/archives/gastrointestinal/examode_biopsies_radboudumc_colon/packed_blocks_sp05/packed/EX_S03_P003909_C0001_B2.tif is just pixelated stuff\n",
    "\n",
    "Are they different in Snellius?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing the process list of feature extraction to process it in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6563\n",
      "Missing to process 0\n",
      "Already processed 6563\n"
     ]
    }
   ],
   "source": [
    "processed_feature=pd.read_csv(f'{running_in}/projects/pathology-self-supervision/data/examode_colon/WSI_experiments/4096_HIPT_TCGA_ckpt/features/process_list_global_pretraining.csv')\n",
    "print(processed_feature.where(processed_feature.process==0).dropna()['process'].count())\n",
    "mask = processed_feature[\"process\"] == 1\n",
    "process_stack = processed_feature[mask]\n",
    "total = len(process_stack)\n",
    "already_processed = len(processed_feature) - total\n",
    "print(f'Missing to process {total}')\n",
    "print(f'Already processed {already_processed}')\n",
    "#take half of the process stack \n",
    "process_stack_2 = process_stack[-int(total/2):].index.tolist()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl_sofi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
